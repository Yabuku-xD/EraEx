{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EraEx: Build FAISS + BM25 Indexes\n",
        "\n",
        "This notebook builds:\n",
        "1. FAISS IVF+PQ indexes for dense retrieval\n",
        "2. BM25 index for sparse retrieval\n",
        "\n",
        "**Supports**: Google Colab, Vast.ai, Local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project: c:\\Users\\Yabuku\\Downloads\\EraEx\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PROJECT_DIR = Path('/content/drive/MyDrive/EraEx')\n",
        "except ImportError:\n",
        "    env_dir = os.environ.get('ERAEX_DIR', '')\n",
        "    if env_dir and Path(env_dir).exists():\n",
        "        PROJECT_DIR = Path(env_dir)\n",
        "    elif Path.cwd().name == 'notebooks':\n",
        "        PROJECT_DIR = Path.cwd().parent\n",
        "    else:\n",
        "        PROJECT_DIR = Path.cwd()\n",
        "\n",
        "print(f\"Project: {PROJECT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: polars in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 1)) (1.37.1)\n",
            "Requirement already satisfied: pyarrow in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 2)) (22.0.0)\n",
            "Requirement already satisfied: fastapi in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 3)) (0.116.1)\n",
            "Requirement already satisfied: uvicorn in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 4)) (0.35.0)\n",
            "Requirement already satisfied: sentence-transformers in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: faiss-cpu in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 6)) (1.13.2)\n",
            "Requirement already satisfied: httpx in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: pydantic in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 8)) (2.12.5)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 11)) (3.1.5)\n",
            "Requirement already satisfied: redis in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 12)) (7.1.0)\n",
            "Requirement already satisfied: nrclex in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 13)) (3.0.0)\n",
            "Requirement already satisfied: bm25s in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 14)) (0.2.14)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 15)) (1.6.1)\n",
            "Requirement already satisfied: zstandard in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 16)) (0.25.0)\n",
            "Requirement already satisfied: transformers in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (4.49.0)\n",
            "Requirement already satisfied: torch in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 18)) (2.9.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 19)) (3.9.2)\n",
            "Requirement already satisfied: guessit in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 20)) (3.8.0)\n",
            "Requirement already satisfied: polars-runtime-32==1.37.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from polars->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 1)) (1.37.1)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 3)) (0.47.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 8)) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 3)) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 4)) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 5)) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 5)) (0.36.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (0.5.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 5)) (2025.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 10)) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from redis->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 12)) (5.0.1)\n",
            "Requirement already satisfied: textblob in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nrclex->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 13)) (0.19.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 15)) (3.5.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 18)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 18)) (3.4.2)\n",
            "Requirement already satisfied: rebulk>=3.2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from guessit->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 20)) (3.2.0)\n",
            "Requirement already satisfied: babelfish>=0.6.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from guessit->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 20)) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from guessit->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil->guessit->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers->-r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt (line 17)) (2.6.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -r C:\\Users\\Yabuku\\Downloads\\EraEx\\requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\embeddings\n",
            "Indexes: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\n",
            "\n",
            "  2012: (12537701, 768)\n",
            "  2013: (10420728, 768)\n",
            "  2014: (2417280, 768)\n",
            "  2015: (2293643, 768)\n",
            "  2016: (1948712, 768)\n",
            "  2017: (1600543, 768)\n",
            "  2018: (1823593, 768)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import faiss\n",
        "import pickle\n",
        "import gc\n",
        "\n",
        "EMBEDDINGS_DIR = PROJECT_DIR / 'data' / 'embeddings'\n",
        "READY_DIR = PROJECT_DIR / 'data' / 'processed' / 'music_ready'\n",
        "INDEXES_DIR = PROJECT_DIR / 'data' / 'indexes'\n",
        "\n",
        "INDEXES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "YEAR_RANGE = range(2012, 2019)\n",
        "\n",
        "N_LIST = 256\n",
        "M_PQ = 48\n",
        "N_BITS = 8\n",
        "ADD_CHUNK = 500_000\n",
        "\n",
        "print(f\"Embeddings: {EMBEDDINGS_DIR}\")\n",
        "print(f\"Indexes: {INDEXES_DIR}\\n\")\n",
        "\n",
        "for y in YEAR_RANGE:\n",
        "    p = EMBEDDINGS_DIR / f'embeddings_{y}.npy'\n",
        "    if p.exists():\n",
        "        emb = np.load(p, mmap_mode='r')\n",
        "        print(f\"  {y}: {emb.shape}\")\n",
        "    else:\n",
        "        print(f\"  {y}: NOT FOUND\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Build FAISS Indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_faiss_index(year):\n",
        "    emb_path = EMBEDDINGS_DIR / f'embeddings_{year}.npy'\n",
        "    idx_path = INDEXES_DIR / f'faiss_{year}.index'\n",
        "\n",
        "    if not emb_path.exists():\n",
        "        print(f'{year}: No embeddings')\n",
        "        return\n",
        "\n",
        "    if idx_path.exists():\n",
        "        print(f'{year}: Index exists, skipping')\n",
        "        return\n",
        "\n",
        "    print(f'\\nBuilding FAISS index for {year}...')\n",
        "    emb_mmap = np.load(emb_path, mmap_mode='r')\n",
        "    n_vectors, dim = emb_mmap.shape\n",
        "    print(f'  Vectors: {n_vectors:,} x {dim}')\n",
        "\n",
        "    n_train = min(n_vectors, 100_000)\n",
        "    train_idx = np.random.choice(n_vectors, n_train, replace=False)\n",
        "    train_data = emb_mmap[train_idx].astype(np.float32)\n",
        "\n",
        "    n_list_actual = min(N_LIST, n_vectors // 50)\n",
        "    m_pq_actual = min(M_PQ, dim)\n",
        "\n",
        "    quantizer = faiss.IndexFlatIP(dim)\n",
        "    index = faiss.IndexIVFPQ(quantizer, dim, n_list_actual, m_pq_actual, N_BITS)\n",
        "\n",
        "    print(f'  Training (n_list={n_list_actual}, m_pq={m_pq_actual})...')\n",
        "    index.train(train_data)\n",
        "    del train_data\n",
        "    gc.collect()\n",
        "\n",
        "    print(f'  Adding vectors in chunks of {ADD_CHUNK:,}...')\n",
        "    for start in range(0, n_vectors, ADD_CHUNK):\n",
        "        end = min(start + ADD_CHUNK, n_vectors)\n",
        "        chunk = emb_mmap[start:end].astype(np.float32)\n",
        "        index.add(chunk)\n",
        "        del chunk\n",
        "        gc.collect()\n",
        "        print(f'    {end:,} / {n_vectors:,}')\n",
        "\n",
        "    del emb_mmap\n",
        "    gc.collect()\n",
        "\n",
        "    faiss.write_index(index, str(idx_path))\n",
        "    print(f'  Saved: {idx_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Building FAISS index for 2012...\n",
            "  Vectors: 12,537,701 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 12,537,701\n",
            "    1,000,000 / 12,537,701\n",
            "    1,500,000 / 12,537,701\n",
            "    2,000,000 / 12,537,701\n",
            "    2,500,000 / 12,537,701\n",
            "    3,000,000 / 12,537,701\n",
            "    3,500,000 / 12,537,701\n",
            "    4,000,000 / 12,537,701\n",
            "    4,500,000 / 12,537,701\n",
            "    5,000,000 / 12,537,701\n",
            "    5,500,000 / 12,537,701\n",
            "    6,000,000 / 12,537,701\n",
            "    6,500,000 / 12,537,701\n",
            "    7,000,000 / 12,537,701\n",
            "    7,500,000 / 12,537,701\n",
            "    8,000,000 / 12,537,701\n",
            "    8,500,000 / 12,537,701\n",
            "    9,000,000 / 12,537,701\n",
            "    9,500,000 / 12,537,701\n",
            "    10,000,000 / 12,537,701\n",
            "    10,500,000 / 12,537,701\n",
            "    11,000,000 / 12,537,701\n",
            "    11,500,000 / 12,537,701\n",
            "    12,000,000 / 12,537,701\n",
            "    12,500,000 / 12,537,701\n",
            "    12,537,701 / 12,537,701\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2012.index\n",
            "\n",
            "Building FAISS index for 2013...\n",
            "  Vectors: 10,420,728 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 10,420,728\n",
            "    1,000,000 / 10,420,728\n",
            "    1,500,000 / 10,420,728\n",
            "    2,000,000 / 10,420,728\n",
            "    2,500,000 / 10,420,728\n",
            "    3,000,000 / 10,420,728\n",
            "    3,500,000 / 10,420,728\n",
            "    4,000,000 / 10,420,728\n",
            "    4,500,000 / 10,420,728\n",
            "    5,000,000 / 10,420,728\n",
            "    5,500,000 / 10,420,728\n",
            "    6,000,000 / 10,420,728\n",
            "    6,500,000 / 10,420,728\n",
            "    7,000,000 / 10,420,728\n",
            "    7,500,000 / 10,420,728\n",
            "    8,000,000 / 10,420,728\n",
            "    8,500,000 / 10,420,728\n",
            "    9,000,000 / 10,420,728\n",
            "    9,500,000 / 10,420,728\n",
            "    10,000,000 / 10,420,728\n",
            "    10,420,728 / 10,420,728\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2013.index\n",
            "\n",
            "Building FAISS index for 2014...\n",
            "  Vectors: 2,417,280 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 2,417,280\n",
            "    1,000,000 / 2,417,280\n",
            "    1,500,000 / 2,417,280\n",
            "    2,000,000 / 2,417,280\n",
            "    2,417,280 / 2,417,280\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2014.index\n",
            "\n",
            "Building FAISS index for 2015...\n",
            "  Vectors: 2,293,643 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 2,293,643\n",
            "    1,000,000 / 2,293,643\n",
            "    1,500,000 / 2,293,643\n",
            "    2,000,000 / 2,293,643\n",
            "    2,293,643 / 2,293,643\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2015.index\n",
            "\n",
            "Building FAISS index for 2016...\n",
            "  Vectors: 1,948,712 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 1,948,712\n",
            "    1,000,000 / 1,948,712\n",
            "    1,500,000 / 1,948,712\n",
            "    1,948,712 / 1,948,712\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2016.index\n",
            "\n",
            "Building FAISS index for 2017...\n",
            "  Vectors: 1,600,543 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 1,600,543\n",
            "    1,000,000 / 1,600,543\n",
            "    1,500,000 / 1,600,543\n",
            "    1,600,543 / 1,600,543\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2017.index\n",
            "\n",
            "Building FAISS index for 2018...\n",
            "  Vectors: 1,823,593 x 768\n",
            "  Training (n_list=256, m_pq=48)...\n",
            "  Adding vectors in chunks of 500,000...\n",
            "    500,000 / 1,823,593\n",
            "    1,000,000 / 1,823,593\n",
            "    1,500,000 / 1,823,593\n",
            "    1,823,593 / 1,823,593\n",
            "  Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\faiss_2018.index\n",
            "\n",
            "FAISS indexes complete!\n"
          ]
        }
      ],
      "source": [
        "for year in YEAR_RANGE:\n",
        "    build_faiss_index(year)\n",
        "\n",
        "print('\\nFAISS indexes complete!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build BM25 Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import bm25s\n",
        "\n",
        "def build_bm25_index():\n",
        "    bm25_path = INDEXES_DIR / 'bm25_index.pkl'\n",
        "    \n",
        "    if bm25_path.exists():\n",
        "        print('BM25 index exists, skipping')\n",
        "        return\n",
        "    \n",
        "    print('Loading all documents for BM25...')\n",
        "    all_docs = []\n",
        "    all_ids = []\n",
        "    \n",
        "    for year in YEAR_RANGE:\n",
        "        data_path = READY_DIR / f'year={year}' / 'data.parquet'\n",
        "        if not data_path.exists():\n",
        "            continue\n",
        "        \n",
        "        df = pl.read_parquet(data_path)\n",
        "        texts = df['doc_text_music'].to_list()\n",
        "        id_col = 'track_id' if 'track_id' in df.columns else 'permalink_url'\n",
        "        ids = df[id_col].to_list()\n",
        "        \n",
        "        all_docs.extend([t if t else '' for t in texts])\n",
        "        all_ids.extend([str(i) for i in ids])\n",
        "        \n",
        "        print(f'  {year}: {len(texts):,} docs')\n",
        "    \n",
        "    print(f'\\nTotal documents: {len(all_docs):,}')\n",
        "    \n",
        "    print('Building BM25 index...')\n",
        "    corpus_tokens = bm25s.tokenize(all_docs)\n",
        "    \n",
        "    bm25 = bm25s.BM25()\n",
        "    bm25.index(corpus_tokens)\n",
        "    \n",
        "    index_data = {\n",
        "        'bm25': bm25,\n",
        "        'doc_ids': all_ids,\n",
        "        'corpus_tokens': corpus_tokens,\n",
        "    }\n",
        "    \n",
        "    with open(bm25_path, 'wb') as f:\n",
        "        pickle.dump(index_data, f)\n",
        "    \n",
        "    print(f'Saved: {bm25_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading all documents for BM25...\n",
            "  2012: 12,537,701 docs\n",
            "  2013: 10,420,728 docs\n",
            "  2014: 2,417,280 docs\n",
            "  2015: 2,293,643 docs\n",
            "  2016: 1,948,712 docs\n",
            "  2017: 1,600,543 docs\n",
            "  2018: 1,823,593 docs\n",
            "\n",
            "Total documents: 33,042,200\n",
            "Building BM25 index...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0ceeea5adf640a5b60b494f6b550140",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Split strings:   0%|          | 0/33042200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77351b5eccfe4f3bbac4d4413cbaf081",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BM25S Count Tokens:   0%|          | 0/33042200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8109f4e520394ca3b1fc38f9e66137db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BM25S Compute Scores:   0%|          | 0/33042200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\indexes\\bm25_index.pkl\n",
            "\n",
            "==================================================\n",
            "ALL INDEXES COMPLETE\n",
            "==================================================\n",
            "bm25_index.pkl: 8831.4 MB\n",
            "faiss_2012.index: 703.7 MB\n",
            "faiss_2013.index: 585.1 MB\n",
            "faiss_2014.index: 136.9 MB\n",
            "faiss_2015.index: 130.0 MB\n",
            "faiss_2016.index: 110.7 MB\n",
            "faiss_2017.index: 91.2 MB\n",
            "faiss_2018.index: 103.7 MB\n"
          ]
        }
      ],
      "source": [
        "build_bm25_index()\n",
        "\n",
        "print('\\n' + '=' * 50)\n",
        "print('ALL INDEXES COMPLETE')\n",
        "print('=' * 50)\n",
        "\n",
        "for f in sorted(INDEXES_DIR.glob('*')):\n",
        "    size_mb = f.stat().st_size / 1e6\n",
        "    print(f'{f.name}: {size_mb:.1f} MB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test query: \"i miss my ex\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c00d2a7f347425e8371c60289f36c85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9909206d350641c193d6e669f427717f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c2a646a47894bde99c60a3d80f0bb05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3144e092a8334d9d929067cf4f3bd846",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "721fc4ceff3d43d48f81d2f390a42778",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10bd7b518c674142b5741528ab64e657",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 5 from 2015:\n",
            "  1. Your Gonna Miss Me When Im Gone - None (score: 0.5763)\n",
            "  2. youll miss me when im gone - None (score: 0.5768)\n",
            "  3. You re Gonna Miss My Love - None (score: 0.5802)\n",
            "  4. You missed me so much - None (score: 0.5802)\n",
            "  5. You missed me so much - None (score: 0.5802)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "test_query = 'i miss my ex'\n",
        "print(f'Test query: \"{test_query}\"')\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained('colbert-ir/colbertv2.0')\n",
        "mdl = AutoModel.from_pretrained('colbert-ir/colbertv2.0')\n",
        "mdl.eval()\n",
        "\n",
        "inputs = tok([test_query], return_tensors='pt', truncation=True, max_length=32)\n",
        "with torch.no_grad():\n",
        "    out = mdl(**inputs)\n",
        "    mask = inputs['attention_mask'].unsqueeze(-1).float()\n",
        "    pooled = (out.last_hidden_state * mask).sum(1) / mask.sum(1)\n",
        "    pooled = pooled / (pooled.norm(dim=1, keepdim=True) + 1e-9)\n",
        "q_emb = pooled.numpy().astype(np.float32)\n",
        "\n",
        "year = 2015\n",
        "idx_path = INDEXES_DIR / f'faiss_{year}.index'\n",
        "if idx_path.exists():\n",
        "    index = faiss.read_index(str(idx_path))\n",
        "    index.nprobe = 10\n",
        "    scores, indices = index.search(q_emb, 5)\n",
        "\n",
        "    ids_df = pl.read_parquet(EMBEDDINGS_DIR / f'ids_{year}.parquet')\n",
        "    track_ids = ids_df['track_id'].to_list()\n",
        "\n",
        "    data_path = READY_DIR / f'year={year}' / 'data.parquet'\n",
        "    df = pl.read_parquet(data_path)\n",
        "\n",
        "    print(f'\\nTop 5 from {year}:')\n",
        "    for i, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
        "        idx = int(idx)\n",
        "        title = df['title'][idx] if idx < df.height else 'N/A'\n",
        "        artist = df['artist'][idx] if idx < df.height else 'N/A'\n",
        "        print(f'  {i+1}. {title} - {artist} (score: {score:.4f})')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
