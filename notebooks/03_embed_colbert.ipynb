{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EraEx: ColBERT Embedding (Colab GPU)\n",
        "\n",
        "This notebook generates ColBERT embeddings for music tracks.\n",
        "\n",
        "**Model**: colbert-ir/colbertv2.0\n",
        "**Fallback**: sentence-transformers/all-MiniLM-L6-v2\n",
        "\n",
        "**Requirements**: GPU runtime (T4 or better)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PROJECT_DIR = Path('/content/drive/MyDrive/EraEx')\n",
        "    print(\"Running on Google Colab\")\n",
        "except ImportError:\n",
        "    if Path.cwd().name == 'notebooks':\n",
        "        PROJECT_DIR = Path.cwd().parent\n",
        "    else:\n",
        "        PROJECT_DIR = Path.cwd()\n",
        "    print(f\"Running Locally at {PROJECT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import gc\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "READY_DIR = PROJECT_DIR / 'data' / 'processed' / 'music_ready'\n",
        "EMBEDDINGS_DIR = PROJECT_DIR / 'data' / 'embeddings'\n",
        "\n",
        "EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "YEAR_RANGE = range(2012, 2019)\n",
        "USE_COLBERT = True\n",
        "EMBED_CHUNK = 500_000\n",
        "\n",
        "print(f'Project Dir: {PROJECT_DIR}')\n",
        "print(f'Data Dir: {READY_DIR}\\n')\n",
        "\n",
        "for y in YEAR_RANGE:\n",
        "    p = READY_DIR / f'year={y}' / 'data.parquet'\n",
        "    if p.exists():\n",
        "        rows = pl.scan_parquet(str(p)).select(pl.len()).collect().item()\n",
        "        print(f'  {y}: {rows:,} rows')\n",
        "    else:\n",
        "        print(f'  {y}: NOT FOUND')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "if USE_COLBERT:\n",
        "    try:\n",
        "        from transformers import AutoTokenizer, AutoModel, logging\n",
        "        \n",
        "        # Suppress HF warnings\n",
        "        logging.set_verbosity_error()\n",
        "        import warnings\n",
        "        warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "        MODEL_NAME = 'colbert-ir/colbertv2.0'\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "        \n",
        "        print(f'Loading {MODEL_NAME}...')\n",
        "        print(\"(Note: Ignore 'UNEXPECTED linear.weight' warnings - normal for Dense mode)\")\n",
        "        \n",
        "        model = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.eval()\n",
        "        EMBEDDER_TYPE = 'colbert'\n",
        "        print(f'âœ“ Model Loaded Successfully')\n",
        "    except Exception as e:\n",
        "        print(f'ColBERT failed: {e}')\n",
        "        print('Falling back to SBERT')\n",
        "        USE_COLBERT = False\n",
        "\n",
        "if not USE_COLBERT:\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    EMBEDDER_TYPE = 'sbert'\n",
        "    print('Using SBERT: all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def embed_sbert(texts, batch_size=512):\n",
        "    embeddings = model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    return embeddings.astype(np.float16)\n",
        "\n",
        "def embed_colbert(texts, batch_size=128):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    all_embeddings = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size)):\n",
        "        batch = texts[i:i + batch_size]\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=180,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            token_emb = outputs.last_hidden_state\n",
        "            mask = inputs['attention_mask']\n",
        "\n",
        "            mask_expanded = mask.unsqueeze(-1).float()\n",
        "            sum_emb = (token_emb * mask_expanded).sum(dim=1)\n",
        "            count = mask_expanded.sum(dim=1)\n",
        "            pooled = sum_emb / count\n",
        "            pooled = pooled / (pooled.norm(dim=1, keepdim=True) + 1e-9)\n",
        "\n",
        "            all_embeddings.append(pooled.cpu().numpy())\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return np.vstack(all_embeddings).astype(np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_year(year):\n",
        "    data_path = READY_DIR / f'year={year}' / 'data.parquet'\n",
        "    if not data_path.exists():\n",
        "        print(f'{year}: Not found at {data_path}')\n",
        "        return\n",
        "\n",
        "    emb_path = EMBEDDINGS_DIR / f'embeddings_{year}.npy'\n",
        "    ids_path = EMBEDDINGS_DIR / f'ids_{year}.parquet'\n",
        "\n",
        "    if emb_path.exists() and ids_path.exists():\n",
        "        print(f'{year}: Already complete, skipping')\n",
        "        return\n",
        "\n",
        "    print(f'\\nProcessing {year}...')\n",
        "    df = pl.read_parquet(data_path)\n",
        "    texts = df['doc_text_music'].fill_null('').to_list()\n",
        "    total = len(texts)\n",
        "    print(f'  Rows: {total:,} | Embedder: {EMBEDDER_TYPE}')\n",
        "\n",
        "    chunk_dir = EMBEDDINGS_DIR / f'chunks_{year}'\n",
        "    chunk_dir.mkdir(exist_ok=True)\n",
        "    n_chunks = (total + EMBED_CHUNK - 1) // EMBED_CHUNK\n",
        "\n",
        "    for c in range(n_chunks):\n",
        "        chunk_path = chunk_dir / f'chunk_{c}.npy'\n",
        "        if chunk_path.exists():\n",
        "            print(f'  Chunk {c+1}/{n_chunks}: already saved, skipping')\n",
        "            continue\n",
        "\n",
        "        start = c * EMBED_CHUNK\n",
        "        end = min(start + EMBED_CHUNK, total)\n",
        "        batch_texts = texts[start:end]\n",
        "\n",
        "        print(f'  Chunk {c+1}/{n_chunks}: embedding {len(batch_texts):,} texts...')\n",
        "        if EMBEDDER_TYPE == 'colbert':\n",
        "            emb = embed_colbert(batch_texts)\n",
        "        else:\n",
        "            emb = embed_sbert(batch_texts)\n",
        "\n",
        "        np.save(chunk_path, emb)\n",
        "        del emb\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    print(f'  Combining {n_chunks} chunks...')\n",
        "    chunks = [np.load(chunk_dir / f'chunk_{c}.npy') for c in range(n_chunks)]\n",
        "    embeddings = np.vstack(chunks)\n",
        "    del chunks\n",
        "    gc.collect()\n",
        "\n",
        "    np.save(emb_path, embeddings)\n",
        "    print(f'  Saved: {emb_path} | Shape: {embeddings.shape}')\n",
        "\n",
        "    ids_df = df.select(['track_id'])\n",
        "    ids_df.write_parquet(ids_path)\n",
        "    print(f'  Saved: {ids_path}')\n",
        "\n",
        "    del embeddings, df, texts\n",
        "    gc.collect()\n",
        "\n",
        "    shutil.rmtree(chunk_dir)\n",
        "    print(f'  Cleaned up temp chunks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for year in YEAR_RANGE:\n",
        "    process_year(year)\n",
        "\n",
        "print('\\n' + '=' * 50)\n",
        "print('EMBEDDING COMPLETE')\n",
        "print('=' * 50)\n",
        "\n",
        "for f in sorted(EMBEDDINGS_DIR.glob('*.npy')):\n",
        "    emb = np.load(f)\n",
        "    print(f'{f.name}: {emb.shape}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
