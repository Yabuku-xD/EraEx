{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EraEx: ColBERT Embedding (Colab GPU)\n",
        "\n",
        "This notebook generates ColBERT embeddings for music tracks.\n",
        "\n",
        "**Model**: colbert-ir/colbertv2.0\n",
        "**Fallback**: sentence-transformers/all-MiniLM-L6-v2\n",
        "\n",
        "**Requirements**: GPU runtime (T4 or better)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PROJECT_DIR = Path('/content/drive/MyDrive/EraEx')\n",
        "    print(\"Running on Google Colab\")\n",
        "except ImportError:\n",
        "    if Path.cwd().name == 'notebooks':\n",
        "        PROJECT_DIR = Path.cwd().parent\n",
        "    else:\n",
        "        PROJECT_DIR = Path.cwd()\n",
        "    print(f\"Running Locally at {PROJECT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "\n",
        "def run_pip(*args):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\"] + list(args))\n",
        "\n",
        "torch_ok = False\n",
        "try:\n",
        "    import torch\n",
        "    torch_ok = True\n",
        "    print(f\"torch {torch.__version__} OK\")\n",
        "except Exception:\n",
        "    print(\"torch is broken from a previous install. Reinstalling...\")\n",
        "    run_pip(\"install\", \"-q\", \"--force-reinstall\", \"torch\", \"torchvision\", \"torchaudio\")\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"TORCH FIXED. Restart runtime and re-run all cells.\")\n",
        "    print(\"Runtime > Restart runtime\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "if torch_ok:\n",
        "    req_path = PROJECT_DIR / \"requirements.txt\"\n",
        "    skip_on_colab = {\"torch\", \"faiss-cpu\", \"torchvision\", \"torchaudio\"}\n",
        "    deps = [l.strip() for l in req_path.read_text().splitlines() if l.strip() and l.strip() not in skip_on_colab]\n",
        "    run_pip(\"install\", \"-q\", \"--no-deps\", \"sentence-transformers\")\n",
        "    run_pip(\"install\", \"-q\", *[d for d in deps if d != \"sentence-transformers\"])\n",
        "    print(\"All dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import polars as pl\n",
        "import gc\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "READY_DIR = PROJECT_DIR / 'data' / 'processed' / 'music_ready'\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    EMBEDDINGS_DIR = Path('/content/embeddings')\n",
        "    print(\"Saving embeddings to LOCAL disk (fast)\")\n",
        "except ImportError:\n",
        "    EMBEDDINGS_DIR = PROJECT_DIR / 'data' / 'embeddings'\n",
        "\n",
        "EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "YEAR_RANGE = range(2012, 2019)\n",
        "USE_COLBERT = True\n",
        "EMBED_CHUNK = 4_000_000\n",
        "\n",
        "print(f'Project Dir: {PROJECT_DIR}')\n",
        "print(f'Data Dir: {READY_DIR}\\n')\n",
        "\n",
        "for y in YEAR_RANGE:\n",
        "    p = READY_DIR / f'year={y}' / 'data.parquet'\n",
        "    if p.exists():\n",
        "        rows = pl.scan_parquet(str(p)).select(pl.len()).collect().item()\n",
        "        print(f'  {y}: {rows:,} rows')\n",
        "    else:\n",
        "        print(f'  {y}: NOT FOUND')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "if USE_COLBERT:\n",
        "    try:\n",
        "        from transformers import AutoTokenizer, AutoModel, logging\n",
        "        \n",
        "        # Suppress HF warnings\n",
        "        logging.set_verbosity_error()\n",
        "        import warnings\n",
        "        warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "        MODEL_NAME = 'colbert-ir/colbertv2.0'\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "        \n",
        "        print(f'Loading {MODEL_NAME}...')\n",
        "        print(\"(Note: Ignore 'UNEXPECTED linear.weight' warnings - normal for Dense mode)\")\n",
        "        \n",
        "        model = AutoModel.from_pretrained(MODEL_NAME, attn_implementation=\"sdpa\")\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        model.to(device)\n",
        "        if device == 'cuda':\n",
        "            model.half()\n",
        "            print(\"fp16 + SDPA (Flash Attention) enabled\")\n",
        "        model.eval()\n",
        "        EMBEDDER_TYPE = 'colbert'\n",
        "        print(f'âœ“ Model Loaded Successfully on {device}')\n",
        "    except Exception as e:\n",
        "        print(f'ColBERT failed: {e}')\n",
        "        print('Falling back to SBERT')\n",
        "        USE_COLBERT = False\n",
        "\n",
        "if not USE_COLBERT:\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    EMBEDDER_TYPE = 'sbert'\n",
        "    print('Using SBERT: all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def embed_sbert(texts, batch_size=512):\n",
        "    embeddings = model.encode(\n",
        "        texts,\n",
        "        batch_size=batch_size,\n",
        "        show_progress_bar=True,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    )\n",
        "    return embeddings.astype(np.float16)\n",
        "\n",
        "def embed_colbert(texts, start_batch_size=16384):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    sort_idx = sorted(range(len(texts)), key=lambda i: len(texts[i]))\n",
        "    sorted_texts = [texts[i] for i in sort_idx]\n",
        "    unsort_idx = np.argsort(sort_idx)\n",
        "\n",
        "    print(\"    Pre-tokenizing...\")\n",
        "    encodings = tokenizer(\n",
        "        sorted_texts,\n",
        "        padding=False,\n",
        "        truncation=True,\n",
        "        max_length=180,\n",
        "    )\n",
        "    del sorted_texts\n",
        "\n",
        "    all_embeddings = []\n",
        "    i = 0\n",
        "    bs = start_batch_size\n",
        "    total = len(texts)\n",
        "    pbar = tqdm(total=total, unit=\"txt\")\n",
        "\n",
        "    while i < total:\n",
        "        batch_enc = {\n",
        "            'input_ids': encodings['input_ids'][i:i + bs],\n",
        "            'attention_mask': encodings['attention_mask'][i:i + bs],\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            inputs = tokenizer.pad(batch_enc, padding='longest', return_tensors='pt').to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                token_emb = outputs.last_hidden_state\n",
        "                mask = inputs['attention_mask']\n",
        "\n",
        "                mask_expanded = mask.unsqueeze(-1)\n",
        "                sum_emb = (token_emb * mask_expanded).sum(dim=1)\n",
        "                count = mask_expanded.sum(dim=1)\n",
        "                pooled = sum_emb / count\n",
        "                pooled = pooled / (pooled.norm(dim=1, keepdim=True) + 1e-9)\n",
        "\n",
        "                all_embeddings.append(pooled.float().cpu().numpy())\n",
        "\n",
        "            done = min(bs, total - i)\n",
        "            pbar.update(done)\n",
        "            i += done\n",
        "\n",
        "        except torch.cuda.OutOfMemoryError:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            bs = max(512, bs // 2)\n",
        "            pbar.set_postfix(bs=bs)\n",
        "\n",
        "    pbar.close()\n",
        "    del encodings\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    embeddings = np.vstack(all_embeddings).astype(np.float16)\n",
        "    return embeddings[unsort_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_year(year):\n",
        "    data_path = READY_DIR / f'year={year}' / 'data.parquet'\n",
        "    if not data_path.exists():\n",
        "        print(f'{year}: Not found at {data_path}')\n",
        "        return\n",
        "\n",
        "    emb_path = EMBEDDINGS_DIR / f'embeddings_{year}.npy'\n",
        "    ids_path = EMBEDDINGS_DIR / f'ids_{year}.parquet'\n",
        "\n",
        "    if emb_path.exists() and ids_path.exists():\n",
        "        print(f'{year}: Already complete, skipping')\n",
        "        return\n",
        "\n",
        "    print(f'\\nProcessing {year}...')\n",
        "    df = pl.read_parquet(data_path)\n",
        "    texts = df['doc_text_music'].fill_null('').to_list()\n",
        "    total = len(texts)\n",
        "    print(f'  Rows: {total:,} | Embedder: {EMBEDDER_TYPE}')\n",
        "\n",
        "    chunk_dir = EMBEDDINGS_DIR / f'chunks_{year}'\n",
        "    chunk_dir.mkdir(exist_ok=True)\n",
        "    n_chunks = (total + EMBED_CHUNK - 1) // EMBED_CHUNK\n",
        "\n",
        "    for c in range(n_chunks):\n",
        "        chunk_path = chunk_dir / f'chunk_{c}.npy'\n",
        "        if chunk_path.exists():\n",
        "            print(f'  Chunk {c+1}/{n_chunks}: already saved, skipping')\n",
        "            continue\n",
        "\n",
        "        start = c * EMBED_CHUNK\n",
        "        end = min(start + EMBED_CHUNK, total)\n",
        "        batch_texts = texts[start:end]\n",
        "\n",
        "        print(f'  Chunk {c+1}/{n_chunks}: embedding {len(batch_texts):,} texts...')\n",
        "        if EMBEDDER_TYPE == 'colbert':\n",
        "            emb = embed_colbert(batch_texts)\n",
        "        else:\n",
        "            emb = embed_sbert(batch_texts)\n",
        "\n",
        "        np.save(chunk_path, emb)\n",
        "        del emb\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    print(f'  Combining {n_chunks} chunks...')\n",
        "    chunks = [np.load(chunk_dir / f'chunk_{c}.npy') for c in range(n_chunks)]\n",
        "    embeddings = np.vstack(chunks)\n",
        "    del chunks\n",
        "    gc.collect()\n",
        "\n",
        "    np.save(emb_path, embeddings)\n",
        "    print(f'  Saved: {emb_path} | Shape: {embeddings.shape}')\n",
        "\n",
        "    id_col = 'track_id' if 'track_id' in df.columns else 'permalink_url'\n",
        "    ids_df = df.select([id_col]).rename({id_col: 'track_id'})\n",
        "    ids_df.write_parquet(ids_path)\n",
        "    print(f'  Saved: {ids_path} (using {id_col})')\n",
        "\n",
        "    del embeddings, df, texts\n",
        "    gc.collect()\n",
        "\n",
        "    shutil.rmtree(chunk_dir)\n",
        "    print(f'  Cleaned up temp chunks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for year in YEAR_RANGE:\n",
        "    process_year(year)\n",
        "\n",
        "print('\\n' + '=' * 50)\n",
        "print('EMBEDDING COMPLETE')\n",
        "print('=' * 50)\n",
        "\n",
        "for f in sorted(EMBEDDINGS_DIR.glob('*.npy')):\n",
        "    emb = np.load(f)\n",
        "    print(f'{f.name}: {emb.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "zip_path = \"/content/embeddings.zip\"\n",
        "subprocess.run([\"zip\", \"-r\", zip_path, str(EMBEDDINGS_DIR)], check=True)\n",
        "\n",
        "zip_size = Path(zip_path).stat().st_size / (1024**3)\n",
        "print(f\"Zipped: {zip_size:.1f} GB\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"Downloading... (check your browser downloads)\")\n",
        "    files.download(zip_path)\n",
        "except ImportError:\n",
        "    print(f\"Not on Colab. Zip saved at: {zip_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
