{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EraEx: Filter & Prep (Automated + Parallel)\n",
                "\n",
                "Filters music tracks using library-based automation. \n",
                "Runs on **Google Colab** (with Drive mount) or Local.\n",
                "\n",
                "**Automation**:\n",
                "- **Genres**: NLTK WordNet\n",
                "- **Filtering**: `guessit` (Parallelized for speed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install polars zstandard nrclex nltk guessit joblib tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Drive Mount Check\n",
                "try:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    PROJECT_DIR = Path('/content/drive/MyDrive/EraEx')\n",
                "    print(\"✓ Running on Google Colab\")\n",
                "except ImportError:\n",
                "    PROJECT_DIR = Path.cwd().parent\n",
                "    print(\"✓ Running Locally\")\n",
                "\n",
                "PROCESSED_DIR = PROJECT_DIR / 'data' / 'processed'\n",
                "MUSIC_DIR = PROCESSED_DIR / 'music_tracks'\n",
                "READY_DIR = PROCESSED_DIR / 'music_ready'\n",
                "\n",
                "MUSIC_DIR.mkdir(parents=True, exist_ok=True)\n",
                "READY_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "YEAR_RANGE = range(2012, 2019)\n",
                "\n",
                "print(f'Project Dir: {PROJECT_DIR}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import polars as pl\n",
                "import nltk\n",
                "from nltk.corpus import wordnet as wn\n",
                "from guessit import guessit\n",
                "from joblib import Parallel, delayed\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "nltk.download('wordnet', quiet=True)\n",
                "nltk.download('omw-1.4', quiet=True)\n",
                "\n",
                "def get_automated_genres():\n",
                "    genres = set()\n",
                "    try:\n",
                "        base = wn.synset('musical_style.n.01')\n",
                "        for syn in base.closure(lambda s: s.hyponyms()):\n",
                "            for lemma in syn.lemmas():\n",
                "                name = lemma.name().replace('_', ' ').lower()\n",
                "                genres.add(name)\n",
                "    except Exception:\n",
                "        return set()\n",
                "    return genres\n",
                "\n",
                "MUSIC_GENRES = get_automated_genres()\n",
                "print(f\"Loaded {len(MUSIC_GENRES)} genres from WordNet.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def is_music_track(row) -> bool:\n",
                "    \"\"\"Thread-safe logic for parallel filtering\"\"\"\n",
                "    title = str(row.get('title', '')).lower()\n",
                "    genre = str(row.get('genre', '')).lower()\n",
                "    \n",
                "    # 1. Faster Check: Explicit Podcast/Interview Keywords (Optimized RegEx fallback)\n",
                "    # Guessit is slow, so we can skip obvious ones if we wanted, but sticking to logic:\n",
                "    \n",
                "    # 2. Guessit\n",
                "    g = guessit(title)\n",
                "    if g.get('type') == 'episode' or 'season' in g or 'episode' in g:\n",
                "        return False\n",
                "\n",
                "    # 3. WordNet Genre confirmation\n",
                "    if genre and (genre in MUSIC_GENRES):\n",
                "        return True\n",
                "    \n",
                "    return True\n",
                "\n",
                "def filter_music_tracks_parallel(df: pl.DataFrame) -> tuple:\n",
                "    print(\"  > Starting parallel filtering (this takes time for guessit)...\")\n",
                "    rows = df.to_dicts()\n",
                "    \n",
                "    # Run is_music_track in parallel\n",
                "    # n_jobs=-1 uses all cores. Adjust if memory issues.\n",
                "    mask = Parallel(n_jobs=-1, batch_size=1000)(\n",
                "        delayed(is_music_track)(row) for row in tqdm(rows, desc=\"Filtering\", unit=\"row\")\n",
                "    )\n",
                "    \n",
                "    music_rows = [r for r, m in zip(rows, mask) if m]\n",
                "    other_rows = [r for r, m in zip(rows, mask) if not m]\n",
                "    \n",
                "    music_df = pl.DataFrame(music_rows, schema=df.schema)\n",
                "    other_df = pl.DataFrame(other_rows, schema=df.schema)\n",
                "    \n",
                "    return music_df, other_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "MAX_DESC_LENGTH = 400\n",
                "def normalize_text(text): return re.sub(r'\\s+', ' ', str(text or '')).strip()\n",
                "def remove_urls(text): return re.sub(r'https?://\\S+|www\\.\\S+', '', str(text or ''))\n",
                "def normalize_tags(tags):\n",
                "    if not tags: return ''\n",
                "    tag_list = re.split(r'[,;|/\\n]+', tags.lower())\n",
                "    junk = {'soundcloud', 'source', 'iphone', 'android', 'recorder'}\n",
                "    cleaned = [t.strip() for t in tag_list if len(t.strip()) > 1 and t.strip() not in junk]\n",
                "    return ' '.join(dict.fromkeys(cleaned))\n",
                "\n",
                "def build_doc_text(row):\n",
                "    parts = []\n",
                "    if row.get('title'): parts.append(f\"TITLE: {normalize_text(row['title'])}\")\n",
                "    if row.get('artist'): parts.append(f\"ARTIST: {normalize_text(row['artist'])}\")\n",
                "    if row.get('genre'): parts.append(f\"GENRE: {row['genre']} {row['genre']}\")\n",
                "    \n",
                "    tags = f\"{row.get('tags', '')} {row.get('inferred_tags', '')}\".strip()\n",
                "    if tags:\n",
                "        normalized = normalize_tags(tags)\n",
                "        if normalized: parts.append(f\"TAGS: {normalized} {normalized}\")\n",
                "            \n",
                "    if row.get('extracted_vibe_text'):\n",
                "        parts.append(f\"VIBE: {remove_urls(row['extracted_vibe_text'])[:MAX_DESC_LENGTH]}\")\n",
                "    if row.get('description'):\n",
                "        parts.append(f\"DESC: {remove_urls(row['description'])[:MAX_DESC_LENGTH]}\")\n",
                "    if row.get('year'):\n",
                "        parts.append(f\"YEAR: {row['year']}\")\n",
                "    return ' '.join(parts)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_year(year):\n",
                "    year_dir = PROCESSED_DIR / f'year={year}'\n",
                "    if not year_dir.exists(): return None\n",
                "    print(f'Processing {year}...')\n",
                "    \n",
                "    parquet_files = [str(f) for f in year_dir.glob('*.parquet')]\n",
                "    if not parquet_files: return None\n",
                "    \n",
                "    try:\n",
                "        df = pl.scan_parquet(parquet_files).collect()\n",
                "    except Exception:\n",
                "        print(\"  > Schema mismatch fallback (loading slow)...\")\n",
                "        dfs = [pl.read_parquet(f) for f in parquet_files]\n",
                "        df = pl.concat(dfs, how='diagonal')\n",
                "\n",
                "    before = df.height\n",
                "    music_df, _ = filter_music_tracks_parallel(df)\n",
                "    print(f'  Filtered: {before:,} -> {music_df.height:,} music tracks')\n",
                "    \n",
                "    if 'permalink_url' in music_df.columns:\n",
                "        music_df = music_df.unique(subset=['permalink_url'], keep='first')\n",
                "        \n",
                "    rows = music_df.to_dicts()\n",
                "    # Parallelize text building too if needed, but usually fast enough\n",
                "    doc_texts = [build_doc_text(row) for row in rows]\n",
                "    music_df = music_df.with_columns([pl.Series('doc_text_music', doc_texts)])\n",
                "    \n",
                "    out_dir = READY_DIR / f'year={year}'\n",
                "    out_dir.mkdir(parents=True, exist_ok=True)\n",
                "    music_df.write_parquet(out_dir / 'data.parquet')\n",
                "    print(f'  Saved: {out_dir / \"data.parquet\"} ({music_df.height:,} rows)')\n",
                "    return music_df.height"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "total = sum(filter(None, [process_year(y) for y in YEAR_RANGE]))\n",
                "print(f'\\nTotal Ready: {total:,}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}