{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EraEx: Filter & Prep (Automated + Parallel)\n",
        "\n",
        "Filters music tracks using library-based automation. \n",
        "Runs on **Google Colab** (with Drive mount) or Local.\n",
        "\n",
        "**Automation**:\n",
        "- **Genres**: NLTK WordNet\n",
        "- **Filtering**: `guessit` (Parallelized for speed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: polars in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 1)) (1.37.1)\n",
            "Requirement already satisfied: pyarrow in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 2)) (22.0.0)\n",
            "Requirement already satisfied: fastapi in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 3)) (0.116.1)\n",
            "Requirement already satisfied: uvicorn in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 4)) (0.35.0)\n",
            "Requirement already satisfied: sentence-transformers in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: faiss-cpu in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 6)) (1.13.2)\n",
            "Requirement already satisfied: httpx in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: pydantic in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 8)) (2.12.5)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 11)) (3.1.5)\n",
            "Requirement already satisfied: redis in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 12)) (7.1.0)\n",
            "Requirement already satisfied: nrclex in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 13)) (3.0.0)\n",
            "Requirement already satisfied: bm25s in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 14)) (0.2.14)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 15)) (1.6.1)\n",
            "Requirement already satisfied: zstandard in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 16)) (0.25.0)\n",
            "Requirement already satisfied: transformers in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 17)) (4.49.0)\n",
            "Requirement already satisfied: torch in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 18)) (2.9.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 19)) (3.9.2)\n",
            "Requirement already satisfied: guessit in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 20)) (3.8.0)\n",
            "Requirement already satisfied: polars-runtime-32==1.37.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from polars->-r ../requirements.txt (line 1)) (1.37.1)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->-r ../requirements.txt (line 3)) (0.47.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->-r ../requirements.txt (line 3)) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 8)) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r ../requirements.txt (line 3)) (4.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ../requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ../requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn->-r ../requirements.txt (line 4)) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn->-r ../requirements.txt (line 4)) (0.14.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers->-r ../requirements.txt (line 5)) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers->-r ../requirements.txt (line 5)) (0.36.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (0.5.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r ../requirements.txt (line 5)) (2025.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->-r ../requirements.txt (line 7)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->-r ../requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->-r ../requirements.txt (line 10)) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->-r ../requirements.txt (line 11)) (3.0.2)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from redis->-r ../requirements.txt (line 12)) (5.0.1)\n",
            "Requirement already satisfied: textblob in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nrclex->-r ../requirements.txt (line 13)) (0.19.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 15)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 15)) (3.5.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r ../requirements.txt (line 18)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r ../requirements.txt (line 18)) (3.4.2)\n",
            "Requirement already satisfied: rebulk>=3.2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from guessit->-r ../requirements.txt (line 20)) (3.2.0)\n",
            "Requirement already satisfied: babelfish>=0.6.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from guessit->-r ../requirements.txt (line 20)) (0.6.1)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from guessit->-r ../requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch->-r ../requirements.txt (line 18)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil->guessit->-r ../requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers->-r ../requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers->-r ../requirements.txt (line 17)) (2.6.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Running Locally at c:\\Users\\Yabuku\\Downloads\\EraEx\n",
            "Processed Dir: c:\\Users\\Yabuku\\Downloads\\EraEx\\data\\processed\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Robust Drive/Local Path Detection\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PROJECT_DIR = Path('/content/drive/MyDrive/EraEx')\n",
        "    print(\"✓ Running on Google Colab\")\n",
        "except ImportError:\n",
        "    # Local Execution: Handle running from root or notebooks folder\n",
        "    if Path.cwd().name == 'notebooks':\n",
        "        PROJECT_DIR = Path.cwd().parent\n",
        "    else:\n",
        "        PROJECT_DIR = Path.cwd()\n",
        "    print(f\"✓ Running Locally at {PROJECT_DIR}\")\n",
        "\n",
        "PROCESSED_DIR = PROJECT_DIR / 'data' / 'processed'\n",
        "MUSIC_DIR = PROCESSED_DIR / 'music_tracks'\n",
        "READY_DIR = PROCESSED_DIR / 'music_ready'\n",
        "\n",
        "MUSIC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "READY_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "YEAR_RANGE = range(2012, 2019)\n",
        "\n",
        "print(f'Processed Dir: {PROCESSED_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 140 genres from WordNet.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import gc\n",
        "import polars as pl\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from guessit import guessit\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "def get_automated_genres():\n",
        "    genres = set()\n",
        "    try:\n",
        "        base = wn.synset('musical_style.n.01')\n",
        "        for syn in base.closure(lambda s: s.hyponyms()):\n",
        "            for lemma in syn.lemmas():\n",
        "                name = lemma.name().replace('_', ' ').lower()\n",
        "                genres.add(name)\n",
        "    except Exception:\n",
        "        return set()\n",
        "    return genres\n",
        "\n",
        "MUSIC_GENRES = get_automated_genres()\n",
        "print(f\"Loaded {len(MUSIC_GENRES)} genres from WordNet.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHUNK_SIZE = 2_000_000\n",
        "\n",
        "EPISODE_PATTERN = r\"\\b(s\\d+\\s*e\\d+|season\\s*\\d+|episode\\s*[\\.\\:#\\-]?\\s*\\d+|ep\\s*[\\.\\:#\\-]?\\s*\\d+)\\b\"\n",
        "\n",
        "def filter_music_tracks(df: pl.DataFrame) -> tuple:\n",
        "    print(f\"  > Filtering {df.height:,} rows (vectorized)...\")\n",
        "\n",
        "    title_lower = df[\"title\"].fill_null(\"\").str.to_lowercase()\n",
        "    genre_lower = df[\"genre\"].fill_null(\"\").str.to_lowercase()\n",
        "\n",
        "    genre_hit = genre_lower.is_in(list(MUSIC_GENRES))\n",
        "    episode_hit = title_lower.str.contains(EPISODE_PATTERN)\n",
        "\n",
        "    keep_mask = genre_hit | ~episode_hit\n",
        "\n",
        "    genre_kept = genre_hit.sum()\n",
        "    episode_removed = (~genre_hit & episode_hit).sum()\n",
        "    print(f\"  > Genre match: {genre_kept:,} | Episode rejected: {episode_removed:,} | Passed through: {(~genre_hit & ~episode_hit).sum():,}\")\n",
        "\n",
        "    music_df = df.filter(keep_mask)\n",
        "\n",
        "    del title_lower, genre_lower, genre_hit, episode_hit, keep_mask\n",
        "    gc.collect()\n",
        "\n",
        "    return music_df, pl.DataFrame(schema=df.schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAX_DESC_LENGTH = 400\n",
        "def normalize_text(text): return re.sub(r'\\s+', ' ', str(text or '')).strip()\n",
        "def remove_urls(text): return re.sub(r'https?://\\S+|www\\.\\S+', '', str(text or ''))\n",
        "def normalize_tags(tags):\n",
        "    if not tags: return ''\n",
        "    tag_list = re.split(r'[,;|/\\n]+', tags.lower())\n",
        "    junk = {'soundcloud', 'source', 'iphone', 'android', 'recorder'}\n",
        "    cleaned = [t.strip() for t in tag_list if len(t.strip()) > 1 and t.strip() not in junk]\n",
        "    return ' '.join(dict.fromkeys(cleaned))\n",
        "\n",
        "def build_doc_text(row):\n",
        "    parts = []\n",
        "    if row.get('title'): parts.append(f\"TITLE: {normalize_text(row['title'])}\")\n",
        "    if row.get('artist'): parts.append(f\"ARTIST: {normalize_text(row['artist'])}\")\n",
        "    if row.get('genre'): parts.append(f\"GENRE: {row['genre']} {row['genre']}\")\n",
        "    \n",
        "    tags = f\"{row.get('tags', '')} {row.get('inferred_tags', '')}\".strip()\n",
        "    if tags:\n",
        "        normalized = normalize_tags(tags)\n",
        "        if normalized: parts.append(f\"TAGS: {normalized} {normalized}\")\n",
        "            \n",
        "    if row.get('extracted_vibe_text'):\n",
        "        parts.append(f\"VIBE: {remove_urls(row['extracted_vibe_text'])[:MAX_DESC_LENGTH]}\")\n",
        "    if row.get('description'):\n",
        "        parts.append(f\"DESC: {remove_urls(row['description'])[:MAX_DESC_LENGTH]}\")\n",
        "    if row.get('year'):\n",
        "        parts.append(f\"YEAR: {row['year']}\")\n",
        "    return ' '.join(parts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_doc_texts_chunked(df: pl.DataFrame) -> list:\n",
        "    total = df.height\n",
        "    all_texts = []\n",
        "    for start in tqdm(range(0, total, CHUNK_SIZE), desc=\"Building doc_text\"):\n",
        "        size = min(CHUNK_SIZE, total - start)\n",
        "        chunk = df.slice(start, size)\n",
        "        rows = chunk.to_dicts()\n",
        "        all_texts.extend(build_doc_text(row) for row in rows)\n",
        "        del rows, chunk\n",
        "        gc.collect()\n",
        "    return all_texts\n",
        "\n",
        "def process_year(year):\n",
        "    year_dir = PROCESSED_DIR / f'year={year}'\n",
        "    if not year_dir.exists(): return None\n",
        "    print(f'\\nProcessing {year}...')\n",
        "\n",
        "    parquet_files = [str(f) for f in year_dir.glob('*.parquet')]\n",
        "    if not parquet_files: return None\n",
        "\n",
        "    try:\n",
        "        df = pl.scan_parquet(parquet_files).collect()\n",
        "    except Exception:\n",
        "        print(\"  > Schema mismatch fallback (loading slow)...\")\n",
        "        dfs = [pl.read_parquet(f) for f in parquet_files]\n",
        "        df = pl.concat(dfs, how='diagonal')\n",
        "\n",
        "    before = df.height\n",
        "    music_df, _ = filter_music_tracks(df)\n",
        "    del df\n",
        "    gc.collect()\n",
        "    print(f'  Filtered: {before:,} -> {music_df.height:,} music tracks')\n",
        "\n",
        "    if 'permalink_url' in music_df.columns:\n",
        "        music_df = music_df.unique(subset=['permalink_url'], keep='first')\n",
        "        print(f'  After dedup: {music_df.height:,} rows')\n",
        "\n",
        "    doc_texts = build_doc_texts_chunked(music_df)\n",
        "    music_df = music_df.with_columns([pl.Series('doc_text_music', doc_texts)])\n",
        "    del doc_texts\n",
        "    gc.collect()\n",
        "\n",
        "    out_dir = READY_DIR / f'year={year}'\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    music_df.write_parquet(out_dir / 'data.parquet')\n",
        "    print(f'  Saved: {out_dir / \"data.parquet\"} ({music_df.height:,} rows)')\n",
        "\n",
        "    row_count = music_df.height\n",
        "    del music_df\n",
        "    gc.collect()\n",
        "    return row_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'process_year' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[43m[\u001b[49m\u001b[43mprocess_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mYEAR_RANGE\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal Ready: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, [\u001b[43mprocess_year\u001b[49m(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m YEAR_RANGE]))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTotal Ready: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'process_year' is not defined"
          ]
        }
      ],
      "source": [
        "total = sum(filter(None, [process_year(y) for y in YEAR_RANGE]))\n",
        "print(f'\\nTotal Ready: {total:,}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
