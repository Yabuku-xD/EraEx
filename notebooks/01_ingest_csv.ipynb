{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EraEx: Combined CSV Ingestion (Local)\n",
                "\n",
                "This notebook reads **BOTH** CSV files and converts them to Parquet:\n",
                "1. `dataset.csv` (existing data)\n",
                "2. `ndjson_converted.csv` (from notebook 01)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: polars in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 1)) (1.37.1)\n",
                        "Requirement already satisfied: pyarrow in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 2)) (22.0.0)\n",
                        "Requirement already satisfied: fastapi in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 3)) (0.116.1)\n",
                        "Requirement already satisfied: uvicorn in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 4)) (0.35.0)\n",
                        "Requirement already satisfied: sentence-transformers in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 5)) (5.2.0)\n",
                        "Requirement already satisfied: faiss-cpu in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 6)) (1.13.2)\n",
                        "Requirement already satisfied: httpx in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 7)) (0.28.1)\n",
                        "Requirement already satisfied: pydantic in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 8)) (2.12.5)\n",
                        "Requirement already satisfied: python-dotenv in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.0.0)\n",
                        "Requirement already satisfied: tqdm in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 10)) (4.67.1)\n",
                        "Requirement already satisfied: jinja2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 11)) (3.1.5)\n",
                        "Requirement already satisfied: redis in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 12)) (7.1.0)\n",
                        "Requirement already satisfied: nrclex in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 13)) (3.0.0)\n",
                        "Requirement already satisfied: bm25s in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 14)) (0.2.14)\n",
                        "Requirement already satisfied: scikit-learn in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 15)) (1.6.1)\n",
                        "Requirement already satisfied: zstandard in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 16)) (0.25.0)\n",
                        "Requirement already satisfied: transformers in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 17)) (4.49.0)\n",
                        "Requirement already satisfied: torch in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 18)) (2.9.1)\n",
                        "Requirement already satisfied: nltk in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r ../requirements.txt (line 19)) (3.9.2)\n",
                        "Requirement already satisfied: polars-runtime-32==1.37.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from polars->-r ../requirements.txt (line 1)) (1.37.1)\n",
                        "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->-r ../requirements.txt (line 3)) (0.47.3)\n",
                        "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->-r ../requirements.txt (line 3)) (4.15.0)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 8)) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 8)) (2.41.5)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 8)) (0.4.2)\n",
                        "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r ../requirements.txt (line 3)) (4.8.0)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ../requirements.txt (line 3)) (3.10)\n",
                        "Requirement already satisfied: sniffio>=1.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ../requirements.txt (line 3)) (1.3.1)\n",
                        "Requirement already satisfied: click>=7.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn->-r ../requirements.txt (line 4)) (8.1.8)\n",
                        "Requirement already satisfied: h11>=0.8 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn->-r ../requirements.txt (line 4)) (0.14.0)\n",
                        "Requirement already satisfied: scipy in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers->-r ../requirements.txt (line 5)) (1.16.3)\n",
                        "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers->-r ../requirements.txt (line 5)) (0.36.0)\n",
                        "Requirement already satisfied: filelock in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (3.17.0)\n",
                        "Requirement already satisfied: numpy>=1.17 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (2.2.6)\n",
                        "Requirement already satisfied: packaging>=20.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (24.2)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (6.0.2)\n",
                        "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (2024.11.6)\n",
                        "Requirement already satisfied: requests in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (2.32.5)\n",
                        "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (0.21.0)\n",
                        "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->-r ../requirements.txt (line 17)) (0.5.2)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r ../requirements.txt (line 5)) (2025.2.0)\n",
                        "Requirement already satisfied: certifi in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->-r ../requirements.txt (line 7)) (2025.1.31)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->-r ../requirements.txt (line 7)) (1.0.7)\n",
                        "Requirement already satisfied: colorama in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->-r ../requirements.txt (line 10)) (0.4.6)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->-r ../requirements.txt (line 11)) (3.0.2)\n",
                        "Requirement already satisfied: async-timeout>=4.0.3 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from redis->-r ../requirements.txt (line 12)) (5.0.1)\n",
                        "Requirement already satisfied: textblob in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nrclex->-r ../requirements.txt (line 13)) (0.19.0)\n",
                        "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 15)) (1.4.2)\n",
                        "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 15)) (3.5.0)\n",
                        "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r ../requirements.txt (line 18)) (1.14.0)\n",
                        "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r ../requirements.txt (line 18)) (3.4.2)\n",
                        "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch->-r ../requirements.txt (line 18)) (1.3.0)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers->-r ../requirements.txt (line 17)) (3.4.1)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yabuku\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers->-r ../requirements.txt (line 17)) (2.6.3)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
                        "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "source": [
                "%pip install -r ../requirements.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CSV files to process:\n",
                        "  ✓ dataset.csv (21.99 GB)\n",
                        "  ✓ ndjson_converted.csv (5.49 GB)\n"
                    ]
                }
            ],
            "source": [
                "# Local setup - no Google Drive mount needed\n",
                "from pathlib import Path\n",
                "import polars as pl\n",
                "from datetime import date\n",
                "import os\n",
                "\n",
                "# Current directory is 'notebooks', so project root is parent\n",
                "PROJECT_DIR = Path.cwd().parent\n",
                "\n",
                "RAW_DIR = PROJECT_DIR / 'data' / 'raw'\n",
                "PROCESSED_DIR = PROJECT_DIR / 'data' / 'processed'\n",
                "\n",
                "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "YEAR_RANGE = range(2012, 2019)\n",
                "\n",
                "CSV_FILES = [\n",
                "    RAW_DIR / 'dataset.csv',\n",
                "    RAW_DIR / 'ndjson_converted.csv'\n",
                "]\n",
                "\n",
                "print('CSV files to process:')\n",
                "for f in CSV_FILES:\n",
                "    if f.exists():\n",
                "        print(f'  ✓ {f.name} ({f.stat().st_size / 1e9:.2f} GB)')\n",
                "    else:\n",
                "        print(f'  ✗ {f.name} (NOT FOUND)')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "COLUMN_MAPPING = {\n",
                "    'id': 'track_id',\n",
                "    'soundcloud_id': 'track_id',\n",
                "    'user': 'artist',\n",
                "    'username': 'artist',\n",
                "    'tag_list': 'tags',\n",
                "    'plays': 'playback_count',\n",
                "    'url': 'permalink_url',\n",
                "    'date': 'created_at',\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def ingest_csv(csv_path: Path, batch_counter: int = 0):\n",
                "    if not csv_path.exists():\n",
                "        print(f'Skipping {csv_path.name} (not found)')\n",
                "        return batch_counter, {}\n",
                "    \n",
                "    print(f'\\nProcessing: {csv_path.name}')\n",
                "    \n",
                "    stats = {year: 0 for year in YEAR_RANGE}\n",
                "    \n",
                "    reader = pl.read_csv_batched(\n",
                "        csv_path,\n",
                "        batch_size=500000,\n",
                "        ignore_errors=True,\n",
                "        truncate_ragged_lines=True,\n",
                "        infer_schema_length=10000\n",
                "    )\n",
                "    \n",
                "    while True:\n",
                "        batches = reader.next_batches(1)\n",
                "        if not batches:\n",
                "            break\n",
                "        \n",
                "        df = batches[0]\n",
                "        \n",
                "        rename_map = {}\n",
                "        for old_col in df.columns:\n",
                "            old_lower = old_col.lower().strip()\n",
                "            if old_lower in COLUMN_MAPPING:\n",
                "                rename_map[old_col] = COLUMN_MAPPING[old_lower]\n",
                "        if rename_map:\n",
                "            df = df.rename(rename_map)\n",
                "        \n",
                "        if 'track_id' not in df.columns:\n",
                "            if 'id' in df.columns:\n",
                "                df = df.rename({'id': 'track_id'})\n",
                "        \n",
                "        if 'track_id' in df.columns:\n",
                "            df = df.with_columns([pl.col('track_id').cast(pl.Utf8)])\n",
                "        \n",
                "        if 'year' not in df.columns and 'created_at' in df.columns:\n",
                "            df = df.with_columns([\n",
                "                pl.col('created_at').cast(pl.Utf8).str.slice(0, 4).cast(pl.Int32, strict=False).alias('year')\n",
                "            ])\n",
                "        \n",
                "        df = df.with_columns([pl.lit(date.today()).alias('ingest_date')])\n",
                "        \n",
                "        for year in YEAR_RANGE:\n",
                "            year_df = df.filter(pl.col('year') == year)\n",
                "            if year_df.height == 0:\n",
                "                continue\n",
                "            \n",
                "            stats[year] += year_df.height\n",
                "            \n",
                "            year_dir = PROCESSED_DIR / f'year={year}'\n",
                "            year_dir.mkdir(parents=True, exist_ok=True)\n",
                "            \n",
                "            batch_counter += 1\n",
                "            out_path = year_dir / f'batch_{batch_counter:05d}.parquet'\n",
                "            \n",
                "            year_df = year_df.with_columns([pl.col('ingest_date').cast(pl.Date)])\n",
                "            year_df.write_parquet(out_path)\n",
                "        \n",
                "        total_so_far = sum(stats.values())\n",
                "        if total_so_far % 500000 == 0:\n",
                "            print(f'  Processed: {total_so_far:,} rows')\n",
                "    \n",
                "    return batch_counter, stats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Processing: dataset.csv\n",
                        "  Total: 40,828,069 rows\n",
                        "\n",
                        "Processing: ndjson_converted.csv\n",
                        "  Processed: 500,000 rows\n",
                        "  Processed: 1,000,000 rows\n",
                        "  Processed: 1,500,000 rows\n",
                        "  Processed: 2,000,000 rows\n",
                        "  Processed: 2,500,000 rows\n",
                        "  Processed: 3,000,000 rows\n",
                        "  Processed: 3,500,000 rows\n",
                        "  Processed: 4,000,000 rows\n",
                        "  Processed: 4,500,000 rows\n",
                        "  Processed: 5,000,000 rows\n",
                        "  Processed: 5,500,000 rows\n",
                        "  Processed: 6,000,000 rows\n",
                        "  Processed: 6,500,000 rows\n",
                        "  Processed: 7,000,000 rows\n",
                        "  Processed: 7,500,000 rows\n",
                        "  Processed: 8,000,000 rows\n",
                        "  Processed: 8,500,000 rows\n",
                        "  Processed: 9,000,000 rows\n",
                        "  Processed: 9,500,000 rows\n",
                        "  Processed: 10,000,000 rows\n",
                        "  Processed: 10,500,000 rows\n",
                        "  Processed: 11,000,000 rows\n",
                        "  Processed: 11,500,000 rows\n",
                        "  Processed: 12,000,000 rows\n",
                        "  Processed: 12,500,000 rows\n",
                        "  Processed: 13,000,000 rows\n",
                        "  Processed: 13,500,000 rows\n",
                        "  Processed: 14,000,000 rows\n",
                        "  Processed: 14,500,000 rows\n",
                        "  Processed: 15,000,000 rows\n",
                        "  Processed: 15,500,000 rows\n",
                        "  Processed: 16,000,000 rows\n",
                        "  Processed: 16,500,000 rows\n",
                        "  Processed: 17,000,000 rows\n",
                        "  Processed: 17,500,000 rows\n",
                        "  Processed: 18,000,000 rows\n",
                        "  Processed: 18,500,000 rows\n",
                        "  Processed: 19,000,000 rows\n",
                        "  Processed: 19,500,000 rows\n",
                        "  Processed: 20,000,000 rows\n",
                        "  Processed: 20,500,000 rows\n",
                        "  Total: 20,717,482 rows\n"
                    ]
                }
            ],
            "source": [
                "batch_counter = 0\n",
                "all_stats = {}\n",
                "\n",
                "for csv_file in CSV_FILES:\n",
                "    batch_counter, stats = ingest_csv(csv_file, batch_counter)\n",
                "    all_stats[csv_file.name] = stats\n",
                "    print(f\"  Total: {sum(stats.values()):,} rows\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================================================\n",
                        "INGEST COMPLETE\n",
                        "==================================================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Yabuku\\AppData\\Local\\Temp\\ipykernel_4104\\2190398296.py:8: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
                        "(Deprecated in version 0.20.5)\n",
                        "  total_rows = sum(pl.scan_parquet(f).select(pl.count()).collect().item() for f in parquet_files)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "year=2012: 18,246,291 rows in 172 files\n",
                        "year=2013: 16,636,024 rows in 174 files\n",
                        "year=2014: 6,546,780 rows in 139 files\n",
                        "year=2015: 6,014,630 rows in 139 files\n",
                        "year=2016: 5,227,711 rows in 139 files\n",
                        "year=2017: 4,216,928 rows in 139 files\n",
                        "year=2018: 4,657,187 rows in 139 files\n",
                        "\n",
                        "Grand Total: 61,545,551 rows\n"
                    ]
                }
            ],
            "source": [
                "print('\\n' + '=' * 50)\n",
                "print('INGEST COMPLETE')\n",
                "print('=' * 50)\n",
                "\n",
                "grand_total = 0\n",
                "for year_dir in sorted(PROCESSED_DIR.glob('year=*')):\n",
                "    parquet_files = list(year_dir.glob('*.parquet'))\n",
                "    total_rows = sum(pl.scan_parquet(f).select(pl.count()).collect().item() for f in parquet_files)\n",
                "    grand_total += total_rows\n",
                "    print(f'{year_dir.name}: {total_rows:,} rows in {len(parquet_files)} files')\n",
                "\n",
                "print(f'\\nGrand Total: {grand_total:,} rows')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
